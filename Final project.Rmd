– Model selection and post-selection inference: In regression modeling, we sometimes want to include only a subset of our variables in the model and would like that decision to be data dependent. 
Two solutions to this problem are forward stepwise selection and backward stepwise selection, in which you fit a sequence of models, either adding or subtracting one variable at a time until some stopping criterion is reached. 
These procedures work for variable selection, but they invalidate the standard methods of inference in linear models. 
2 You will: 
– Write code implementing either forward stepwise selection or backward stepwise selection. 
 – Set up a simulation experiment, run your method on simulated data, obtain p-values or confidence intervals in the selected model.
----------------------------------


#data generating
-Set the model
```{r}
#simple setup: standard linear model Y=Xβ+ε. 

set.seed(610)

n <- 100
p <- 10 

X <- matrix(rnorm(n*p), n, p)
beta <- c(1, -1, rep(0, p-2))
e <- rnorm(n)
y <- X %*% beta + e  
```


#implement stepwise: backward stepwise selection 
-add or remove one variable at a time 
```{r}
#approach: remove one predictor at a time based on the smallest RSS

backward_stepwise <- function(dat) {
  cols <- names(dat)
  pred <- cols[cols != "y"]

  while (TRUE) {
    k <- length(pred)
    if (k == 0) break

    fm <- paste(pred, collapse = "+")

    form <- as.formula(paste("y ~", fm))
    model <- lm(form, dat)

    if (k == 1) break

        rss_vec <- numeric(k)
    
    for (i in 1:k) {
      nw_pred <- pred[-i]
      nw_fm <- paste(nw_pred, collapse = "+")
      nw_form <- as.formula(paste("y ~", nw_fm))
      nw_model <- lm(nw_form, dat)
      rss_vec[i] <- sum(nw_model$residuals^2)
    }

    rss_min <- which.min(rss_vec)
    pred <- pred[-rss_min]
  }

  model
}
```


#Simulation with the final model
```{r}
#sim
set.seed(610)
n <- 100
p <- 10
beta_true <- c(1, -1, rep(0, p - 2))

simulation_num <- 1000

#p-value & variable selection 
select_matrix <- matrix(0, nrow = simulation_num, ncol = 10)
colnames(select_matrix) <- paste0("X", 1:10)

p_matrix <- matrix(NA, nrow = simulation_num, ncol = 2)
colnames(p_matrix) <- c("X1", "X2")

#simulation 
for (i in 1:simulation_num) {
  X <- matrix(rnorm(n * p), n, p)
  e <- rnorm(n)
  y <- X %*% beta_true + e  

  dat <- data.frame(y = as.numeric(y), X)
  colnames(dat) <- c("y", paste0("X", 1:p))

  model <- backward_stepwise(dat)

  
  vars <- names(coef(model))[-1]
  
  if (length(vars) > 0) {
    select_matrix[i, vars] <- 1
  }
  
  
  sm <- summary(model)$coefficients
  rowname <- rownames(sm)
  for (k in 1:length(rowname)) {
    if (rowname[k] == "X1") {
      p_matrix[i, "X1"] <- sm[k, 4]
    }
        if (rowname[k] == "X2") {
      p_matrix[i, "X2"] <- sm[k, 4]
    }
  }
}

select_prob <- apply(select_matrix, 2, mean)
select_prob

p1 <- p_matrix[, "X1"]
p2 <- p_matrix[, "X2"]

mean(p1 < 0.05, na.rm = TRUE)
mean(p2 < 0.05, na.rm = TRUE)

hist(p1)
hist(p2)

```

#Summarize and interpret results

https://cran.r-project.org/web/packages/MASS/MASS.pdf

1) Venables, W. N., & Ripley, B. D. (2025). MASS: Support Functions and Datasets for Venables and Ripley's MASS (Version 7.3-65). https://cran.r-project.org/package=MASS

step AIC : 최적 모델 찾는 셀렉션 함수 
For comparison, model selection can also be based on Akaike’s Information Criterion (AIC), which provides an alternative stepwise selection approach.

 

https://cran.r-project.org/web/packages/selectiveInference/selectiveInference.pdf?utm_source=chatgpt.com

2) Tibshirani, R., Tibshirani, R., Taylor, J., Loftus, J., Reid, S., & Markovic, J. (2025). selectiveInference: Tools for Post-Selection Inference (Version 1.2-5). https://cran.r-project.org/package=selectiveInference

Details
This function computes selective p-values and confidence intervals (selection intervals) for forward
stepwise regression. The default is to report the results for each predictor after its entry into the
model. See the "type" argument for other options. The confidence interval construction involves
numerical search and can be fragile: if the observed statistic is too close to either end of the truncation interval (vlo and vup, see references), then one or possibly both endpoints of the interval
of desired coverage cannot be computed, and default to +/- Inf. The output tailarea gives the
achieved Gaussian tail areas for the reported intervals—these should be close to alpha/2, and can be
used for error-checking purposes. - 16pg
-> The idea of treating the p-values along the selection path as a sequence is related to the ForwardStop rule (G’Sell et al., 2014), as implemented by the forwardStop function in the selectiveInference package.

